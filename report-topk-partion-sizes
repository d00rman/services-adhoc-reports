#!/usr/bin/env python


import datetime
import operator
import re
import requests


# XXX: Logstash? LogstashSearch?
class Search(object):
    page_size = 200

    def __init__(self, index, host, port=9200):
        self.index = index
        self.host = host
        self.port = port

    def __url(self):
        return "http://{}:{}/{}/_search".format(self.host, self.port, self.index)

    def search(self, query):
        if not isinstance(query, dict):
            raise RuntimeError("invalid argument; query must be a dictionary")
        query["from"] = 0
        query["size"] = Search.page_size
        res = Results(requests.get(self.__url(), json=query))
        for hit in res.hits:
            yield hit
        for _ in range((res.total / Search.page_size) + 1):
            query["from"] += len(res.hits)
            res = Results(requests.get(self.__url(), json=query))
            for hit in res.hits:
                yield hit

# TODO: Add proper error handling
# TODO: Read-only properties?
# XXX: Page? LogstashPage?
class Results(object):
    def __init__(self, response):
        assert response.status_code == 200
        json_response = response.json()
        assert json_response.has_key("timed_out")
        assert not json_response["timed_out"]
        assert json_response.has_key("hits")
        assert json_response["hits"].has_key("total")
        assert json_response["hits"].has_key("hits")
        assert isinstance(json_response["hits"]["hits"], list)

        self.total = json_response["hits"]["total"]
        self.hits = json_response["hits"]["hits"]


# XXX: search_query
def search_request(cluster="eqiad"):
    return {
        "query": {
            "bool": {
                "must": [
                    {"match": {"logger_name": "org.apache.cassandra.io.sstable.format.big.BigTableWriter"}},
                    {"match": {"cluster": cluster}},
                    {"match_phrase": {"message": "Writing large partition"}}
                ]
            }
        },
        "_source": ["message"]
    }

# XXX: yield instead of list?
def index_names(days=7):
    name = lambda dt: dt.strftime("logstash-%Y.%m.%d")
    now = datetime.datetime.now()
    names = [name(now)]
    for i in range(days):
        names.append(name(now - datetime.timedelta(days=i+1)))
    return names

def strfsize(num, suffix='B'):
    for unit in ['', 'Ki', 'Mi', 'Gi', 'Ti', 'Pi', 'Ei', 'Zi']:
        if abs(num) < 1024.0:
            return "%.1f%s%s" % (num, unit, suffix)
        num /= 1024.0
    return "%.1f%s%s" % (num, 'Yi', suffix)

# TODO: argument parsing for host, port, k, (email address?)
# TODO: make it email a report
# TODO: Pretty formatting of sizes

def parse_arguments():
    pass

def main():
    import sys; host = sys.argv[1]
    k = 10
    count = 0
    log = re.compile(r"Writing large partition (?P<partition>.+) \((?P<bytes>[\d]+) bytes\)")
    for index in index_names():
        results = {}
        for hit in Search(index, host).search(search_request()):
            count += 1
            message = hit["_source"]["message"]
            match = log.match(message)
            if not match:
                continue   # XXX: Warn or something?
            partition = match.group("partition")
            size = match.group("bytes")
            if results.get(partition, 0) < size:
                results[partition] = int(size)
        values = sorted(results.items(), key=operator.itemgetter(1), reverse=True)
        print "Processed {} log entries.".format(count)
        print "{} unique partitions.".format(len(values))
        for i in range(k):
            print u"{}: {}".format(strfsize(values[i][1]), values[i][0])
        #print values[:k]
        #print values[-1:]
        break

if __name__ == "__main__":
    main()
